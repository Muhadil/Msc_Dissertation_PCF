{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_df=pd.read_csv('supervised_learning_dataset.csv')\n",
    "supervised_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(supervised_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_df_columns=supervised_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "supervised_df.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_check(i,data):\n",
    "    print(data[i].isna().sum())\n",
    "for i in supervised_df_columns:\n",
    "    missing_check(i,supervised_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualisation of Dataset to get insights into data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot(x=supervised_df['pca_clusters'],palette='rocket')\n",
    "plt.xticks(rotation=270);\n",
    "#plt.savefig('Fig_1.png',bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`The above visualization shows that it is an imbalanced dataset`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values=supervised_df.isna().sum()\n",
    "missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Defining Features and Lables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40) # To make results reproduceable\n",
    "x=supervised_df.drop('pca_clusters',axis=1) #features\n",
    "y=supervised_df['pca_clusters'] # Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=y.to_frame('pca_clusters')\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test, y_train, y_test= train_test_split (x,y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print('*********')\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plotting the labels of train validation and test split to get an insight wether the classes are balanced or not in different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(nrows=1,ncols=2,figsize=(15,5))\n",
    "sns.countplot(x='pca_clusters',data=y_train,ax=ax[0],palette='rocket')\n",
    "ax[0].set_title('Training_Labels')\n",
    "sns.countplot(x='pca_clusters',data=y_test,ax=ax[1],palette='rocket').set(ylabel=None)\n",
    "ax[1].set_title('Test_Labels');\n",
    "#plt.savefig('Label_values.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data Balancing, Duplicate Rows Removal and Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Checking and  Removing Duplicate Rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As Duplicate samples bring biasness in the DataSet so I am checking and Dropping the duplicate rows from the x_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_train))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_check=x_train.duplicated()\n",
    "duplicated_check[duplicated_check=='True']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no duplicate rows in a dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()\n",
    "print(len(x_train))\n",
    "print(len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(y_train.value_counts()*100)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot('pca_clusters',data=y_train,palette=\"rocket\")\n",
    "plt.title('Training set before Balancing')\n",
    "#plt.savefig('Unbalanced_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "#label_up_sample={1:15182 ,1:14245,0:7920,3:982}\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "SMOTEE = SMOTE()\n",
    "\n",
    "x_train, y_train = SMOTEE.fit_resample(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SMOTE` will try to upsampled the minority to the majority. In my case it will bring all samples to 23847 examples because I am choosing default strategy. Smoteing does not generate the replicated sample but instead it will generate new samples bases on the values of the previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### After Balancing\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot('pca_clusters',data=y_train,palette=\"rocket\")\n",
    "plt.title('Training set after Balancing');\n",
    "#plt.savefig('balanced_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Modles Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'Support_vector_machine':SVC(),\n",
    "    'KN_Classifeir':KNeighborsClassifier(),\n",
    "    'Naive_B':GaussianNB(),\n",
    "    'Logistic_Regre':LogisticRegression(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_States=[10,45,80,200,600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "for name,model in models.items():\n",
    "    model.fit(x_train,y_train)\n",
    "    print(f\"{name} accuracy on train set is: {model.score(x_train, y_train) * 100}%\")\n",
    "    print(f\"{name} accuracy on test set is: {model.score(x_test, y_test) * 100}%\")\n",
    "    print('**************************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_accuracy=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in random_States:\n",
    "    clf=LogisticRegression(random_state=i)\n",
    "    clf.fit(x_train,y_train)\n",
    "    predics=clf.predict(x_test)\n",
    "    accuracyy=accuracy_score(y_test,predics)\n",
    "    test_set_accuracy.append(accuracyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Base Line Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_auc_score, roc_curve,plot_confusion_matrix,f1_score,recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Model Accuracy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(random_state=42)\n",
    "clf.fit(x_train,y_train)\n",
    "y_test_preds=clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Confusion Matrix`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A confusion matrix is a quick way to compare the labels a model predicts and the actual labels it was supposed to predict. In essence, giving me an idea of where the model is getting confused."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion=confusion_matrix(y_test, y_test_preds)\n",
    "confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualisation_conf_mat_by_seaborn(conf_mat):\n",
    "\n",
    "    plt.figure(figsize=(4,4))\n",
    "    sns.heatmap(conf_mat,\n",
    "                annot=True,  \n",
    "                cbar=False,\n",
    "               fmt='.0f',)\n",
    "    plt.title('Confusion Matrix Before Tunning Model (Test Set)')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.ylabel('True label');\n",
    "    #plt.savefig('New_Confusion_matrix_1.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualisation_conf_mat_by_seaborn(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classi=classification_report(y_test,y_test_preds)\n",
    "print(classi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Precision - Indicates the proportion of positive identifications (model predicted class 1) which were actually correct. A model which produces no false positives has a precision of 1.0.\n",
    "    Recall - Indicates the proportion of actual positives which were correctly classified. A model which produces no false negatives has a recall of 1.0.\n",
    "    F1 score - A combination of precision and recall. A perfect model achieves an F1 score of 1.0.\n",
    "    Support - The number of samples each metric was calculated on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Area Under Receiver Operating Characteristic (ROC) Curve\n",
    "\n",
    "ROC curves are a comparison of true postive rate (tpr) versus false positive rate (fpr)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am going here with the default values of threshold of Logistic Regression which is `0.5` because in a my dataset it is more important to know both failure and good . So I am not changing the threshold value and shifting it to give more weight to either side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_proba_1=clf.predict_proba(x_test)\n",
    "y_test_proba_1[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "from sklearn.metrics import plot_roc_curve\n",
    "skplt.metrics.plot_roc_curve(y_test, y_test_proba_1,title='ROC Curves (Test set)',curves=( 'each_class'));\n",
    "#plt.savefig('roc_1_new.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised Learning Accuracy Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 70_30_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_70,x_test_30, y_train_70, y_test_30= train_test_split (x,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(40)\n",
    "#label_up_sample={1:15182 ,1:14245,0:7920,3:982}\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "SMOTEE = SMOTE()\n",
    "\n",
    "x_train_70, y_train_70 = SMOTEE.fit_resample(x_train_70, y_train_70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### After Balancing\n",
    "print(x_train_70.shape,y_train_70.shape)\n",
    "print(y_train_70.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.countplot('pca_clusters',data=y_train_70,palette=\"rocket\")\n",
    "plt.title('Training set after Balancing');\n",
    "#plt.savefig('balanced_1.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(random_state=35)\n",
    "clf.fit(x_train_70,y_train_70)\n",
    "predics_30=clf.predict(x_test_30)\n",
    "accuracyy_30=accuracy_score(y_test_30,predics_30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyy_30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 50_50_SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_50,x_test_50, y_train_50, y_test_50= train_test_split (x,y, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "#label_up_sample={1:15182 ,1:14245,0:7920,3:982}\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "SMOTEE = SMOTE()\n",
    "\n",
    "x_train_50, y_train_50 = SMOTEE.fit_resample(x_train_50, y_train_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### After Balancing\n",
    "print(x_train_50.shape,y_train_50.shape)\n",
    "print(y_train_50.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(random_state=12)\n",
    "clf.fit(x_train_50,y_train_50)\n",
    "predics_50=clf.predict(x_test_50)\n",
    "accuracyy_50=accuracy_score(y_test_50,predics_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyy_50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 40_60_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(2)\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train_40,x_test_60, y_train_40, y_test_60= train_test_split (x,y, test_size=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12)\n",
    "#label_up_sample={1:15182 ,1:14245,0:7920,3:982}\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "SMOTEE = SMOTE()\n",
    "\n",
    "x_train_40, y_train_40 = SMOTEE.fit_resample(x_train_40, y_train_40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf=LogisticRegression(random_state=12)\n",
    "clf.fit(x_train_40,y_train_40)\n",
    "predics_60=clf.predict(x_test_60)\n",
    "accuracyy_60=accuracy_score(y_test_60,predics_60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyy_60"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
